{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification \n",
    "\n",
    "* Dataset: [Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "* **Images**: Matrix of numbers (pixels). Each pixel holds a number we will work with\n",
    "* **Images with colors**: Multi channel. 3 values needed.\n",
    "* **Greyscale images**: Single channel images. 1 value needed.\n",
    "* Every image is 28x28 pixels.\n",
    "\n",
    "# 4 values\n",
    "\n",
    "* **List of images**: (1, 2, 3, 4)\n",
    "* **Value 1**: Number of images in the list\n",
    "* **Value 2,3**: Height and width of the image\n",
    "* **Value 4**: Number of channels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "data = 'mnist.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df[df.columns[1:]]\n",
    "\n",
    "# Labels\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>2.321200</td>\n",
       "      <td>5.457800</td>\n",
       "      <td>...</td>\n",
       "      <td>34.320800</td>\n",
       "      <td>23.071900</td>\n",
       "      <td>16.432000</td>\n",
       "      <td>17.870600</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>17.790200</td>\n",
       "      <td>8.353500</td>\n",
       "      <td>2.541600</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.06560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.525187</td>\n",
       "      <td>2.494315</td>\n",
       "      <td>2.208882</td>\n",
       "      <td>4.669183</td>\n",
       "      <td>5.657849</td>\n",
       "      <td>8.591731</td>\n",
       "      <td>15.031508</td>\n",
       "      <td>23.359019</td>\n",
       "      <td>...</td>\n",
       "      <td>57.888679</td>\n",
       "      <td>49.049749</td>\n",
       "      <td>42.159665</td>\n",
       "      <td>44.140552</td>\n",
       "      <td>51.706601</td>\n",
       "      <td>45.128107</td>\n",
       "      <td>28.765769</td>\n",
       "      <td>16.417363</td>\n",
       "      <td>7.462533</td>\n",
       "      <td>1.93403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>107.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.000400      0.010300      0.052100      0.077000   \n",
       "std        2.872425      0.024493      0.525187      2.494315      2.208882   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000      2.000000     45.000000    218.000000    185.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.208600      0.349200      0.826700      2.321200      5.457800   \n",
       "std        4.669183      5.657849      8.591731     15.031508     23.359019   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    223.000000    247.000000    218.000000    244.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     34.320800     23.071900     16.432000     17.870600   \n",
       "std    ...     57.888679     49.049749     42.159665     44.140552   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     55.000000      6.000000      0.000000      0.000000   \n",
       "max    ...    254.000000    252.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      22.860000     17.790200      8.353500      2.541600      0.629500   \n",
       "std       51.706601     45.128107     28.765769     16.417363      7.462533   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    240.000000    225.000000    205.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  10000.00000  \n",
       "mean       0.06560  \n",
       "std        1.93403  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      107.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us scale our data as we can see the variance of the mean.\n",
    "Let's scale the pictures so they are at a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fit_scaler = scaler.fit(X)\n",
    "scaled_pixels = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def display_image(features, image_label):\n",
    "\n",
    "    # Labels\n",
    "    label_names = {\n",
    "        0: 'T-shirt',\n",
    "        1: 'Trouser',\n",
    "        2: 'Pullover',\n",
    "        3: 'Dress',\n",
    "        4: 'Coat',\n",
    "        5: 'Sandal',\n",
    "        6: 'Shirt',\n",
    "        7: 'Sneaker',\n",
    "        8: 'Bag',\n",
    "        9: 'Ankle boot'\n",
    "    }\n",
    "    \n",
    "    print('This is a', label_names[image_label].lower())\n",
    "    plt.imshow(features.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test to display image\n",
    "display_image(X.loc[5].values, y.loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our data\n",
    "We will go ahead and split our data into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Helena\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='sag', multi_class='auto', max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 78.325%\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict, normalize=True)\n",
    "print(f'Accuracy of model: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network comparision\n",
    "CNN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 784])\n",
      "X_test:  torch.Size([4000, 784])\n",
      "y_train:  torch.Size([6000])\n",
      "y_test:  torch.Size([4000])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float)\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float)\n",
    "print(\"X_test: \", X_test_tensor.shape)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "print(\"y_train: \", y_train_tensor.shape)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "print(\"y_test: \", y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape images to 1, 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 1, 28, 28])\n",
      "X_test:  torch.Size([4000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.Tensor(X_train_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "X_test_tensor = torch.Tensor(X_test_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "print(\"X_test: \", X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check number of labels: 10\n"
     ]
    }
   ],
   "source": [
    "# Input size, for grayscale 1 and for color 3\n",
    "input_size = 1\n",
    "\n",
    "# Hidden layers\n",
    "hidden_1 = 1\n",
    "hidden_2 = 32\n",
    "\n",
    "# Output values, we have 10 different labels\n",
    "print(f'Check number of labels: {len(df[\"label\"].unique())}')\n",
    "output = 10\n",
    "      \n",
    "nn_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_1, nn_size),\n",
    "            nn.BatchNorm2d(hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_2, nn_size),\n",
    "            nn.BatchNorm2d(hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Final layer\n",
    "        self.final_layer = nn.Linear(512, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer_1(x)\n",
    "        print(\"Layer 1: \", out.shape)\n",
    "\n",
    "        out = self.layer_2(out)\n",
    "        print(\"Layer 2: \", out.shape)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.final_layer(out)\n",
    "        print(\"Final layer: \", out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to cuda\n",
    "model = CNN_Model()\n",
    "model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move X and y to cuda\n",
    "X_train_tensor = X_train_tensor.to(cuda)\n",
    "X_test_tensor = X_test_tensor.to(cuda)\n",
    "\n",
    "y_train_tensor = y_train_tensor.to(cuda)\n",
    "y_test_tensor = y_test_tensor.to(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 1 Loss 0.5122336745262146\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 2 Loss 0.5102289915084839\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 3 Loss 0.508249044418335\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 4 Loss 0.506294846534729\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 5 Loss 0.5043638348579407\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 6 Loss 0.5024544596672058\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 7 Loss 0.5005643963813782\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 8 Loss 0.49869275093078613\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 9 Loss 0.4968380928039551\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 10 Loss 0.49500417709350586\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 11 Loss 0.4931865632534027\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 12 Loss 0.4913816750049591\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 13 Loss 0.48959264159202576\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 14 Loss 0.4878191649913788\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 15 Loss 0.48606348037719727\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 16 Loss 0.48432686924934387\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 17 Loss 0.482604444026947\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 18 Loss 0.48089730739593506\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 19 Loss 0.47920331358909607\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 20 Loss 0.47752371430397034\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 21 Loss 0.47586071491241455\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 22 Loss 0.47421374917030334\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 23 Loss 0.47258198261260986\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 24 Loss 0.4709624946117401\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 25 Loss 0.46935832500457764\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 26 Loss 0.4677671194076538\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 27 Loss 0.4661887586116791\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 28 Loss 0.46462276577949524\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 29 Loss 0.4630710482597351\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 30 Loss 0.4615322947502136\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 31 Loss 0.46000468730926514\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 32 Loss 0.45848900079727173\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 33 Loss 0.45698633790016174\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 34 Loss 0.45549750328063965\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 35 Loss 0.4540215730667114\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 36 Loss 0.45255643129348755\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 37 Loss 0.4511019289493561\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 38 Loss 0.4496583342552185\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 39 Loss 0.44822433590888977\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 40 Loss 0.44680073857307434\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 41 Loss 0.44538944959640503\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 42 Loss 0.4439903497695923\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 43 Loss 0.44260159134864807\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 44 Loss 0.441223680973053\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 45 Loss 0.43985649943351746\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 46 Loss 0.43849846720695496\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 47 Loss 0.4371481239795685\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 48 Loss 0.43580639362335205\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 49 Loss 0.43447229266166687\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 50 Loss 0.43314531445503235\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 51 Loss 0.4318273961544037\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 52 Loss 0.4305194616317749\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 53 Loss 0.4292202293872833\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 54 Loss 0.42792749404907227\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 55 Loss 0.42664217948913574\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Loss 0.42536357045173645\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 57 Loss 0.4240924119949341\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 58 Loss 0.42282792925834656\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 59 Loss 0.4215727150440216\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 60 Loss 0.42032742500305176\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 61 Loss 0.4190911054611206\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 62 Loss 0.41786253452301025\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 63 Loss 0.4166417717933655\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 64 Loss 0.4154285192489624\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 65 Loss 0.4142242968082428\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 66 Loss 0.4130280315876007\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 67 Loss 0.4118386209011078\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 68 Loss 0.41065648198127747\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 69 Loss 0.40948227047920227\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 70 Loss 0.40831640362739563\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 71 Loss 0.407155305147171\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 72 Loss 0.4060019254684448\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 73 Loss 0.4048556685447693\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 74 Loss 0.4037160575389862\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 75 Loss 0.4025808870792389\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 76 Loss 0.40145134925842285\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 77 Loss 0.4003276228904724\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 78 Loss 0.39920932054519653\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 79 Loss 0.3980957567691803\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 80 Loss 0.39698705077171326\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 81 Loss 0.39588281512260437\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 82 Loss 0.39478442072868347\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 83 Loss 0.3936917185783386\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 84 Loss 0.3926066756248474\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 85 Loss 0.3915274739265442\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 86 Loss 0.39045435190200806\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 87 Loss 0.38938722014427185\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 88 Loss 0.3883250653743744\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 89 Loss 0.3872684836387634\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 90 Loss 0.386217325925827\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 91 Loss 0.38516974449157715\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 92 Loss 0.3841286897659302\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 93 Loss 0.3830929696559906\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 94 Loss 0.3820629119873047\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 95 Loss 0.38103803992271423\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 96 Loss 0.38001981377601624\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 97 Loss 0.37900662422180176\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 98 Loss 0.3779992163181305\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 99 Loss 0.37699776887893677\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_list = list()\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    # Calculate output and loss\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Zero out gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pas\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch} Loss {loss.item()}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (9,) and (99,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-39be1770e75f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'go--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'purple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2840\u001b[0m     return gca().plot(\n\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2842\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (9,) and (99,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAHWCAYAAACBqMQDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS40lEQVR4nO3dX4ild33H8c+3uwb8VyNmKzZ/MJRoTMEUHaMXirHSmuSioWAhUZQGYQk14qW50gtv6oUgYnRZJARvzEUNGks09EYtxNBsQKMxRJaEJtsISVQsKDRs8u3FjGU6nm/mZHLmzLp5vWBhn+f85swX5sfum2efPU91dwAAgD/0Jwc9AAAAnKnEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMdo3lqrq1qp6sqp8Or1dVfbGqTlbVA1X1ttWPCQAA67fMleXbklz1PK9fneSSrV9Hk3zlxY8FAAAHb9dY7u4fJPnV8yy5NsnXetO9Sc6tqjesakAAADgoq7hn+fwkj287PrV1DgAA/qgdXsF71IJzC5+hXVVHs3mrRl75yle+/dJLL13BtwcAgNn999//dHcf2cvXriKWTyW5cNvxBUmeWLSwu48nOZ4kGxsbfeLEiRV8ewAAmFXVf+71a1dxG8adST669akY70rym+7+xQreFwAADtSuV5ar6utJrkxyXlWdSvKZJC9Lku4+luSuJNckOZnkd0lu2K9hAQBgnXaN5e6+fpfXO8nHVzYRAACcITzBDwAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZLxXJVXVVVD1fVyaq6ecHrr6mqb1fVj6vqwaq6YfWjAgDAeu0ay1V1KMktSa5OclmS66vqsh3LPp7kZ919eZIrk3y+qs5Z8awAALBWy1xZviLJye5+pLufSXJ7kmt3rOkkr66qSvKqJL9KcnqlkwIAwJotE8vnJ3l82/GprXPbfSnJW5I8keQnST7Z3c+tZEIAADggy8RyLTjXO44/kORHSf48yV8l+VJV/ekfvFHV0ao6UVUnnnrqqRc4KgAArNcysXwqyYXbji/I5hXk7W5IckdvOpnk0SSX7nyj7j7e3RvdvXHkyJG9zgwAAGuxTCzfl+SSqrp46z/tXZfkzh1rHkvy/iSpqtcneXOSR1Y5KAAArNvh3RZ09+mquinJ3UkOJbm1ux+sqhu3Xj+W5LNJbquqn2Tzto1PdffT+zg3AADsu11jOUm6+64kd+04d2zb759I8rerHQ0AAA6WJ/gBAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAYKlYrqqrqurhqjpZVTcPa66sqh9V1YNV9f3VjgkAAOt3eLcFVXUoyS1J/ibJqST3VdWd3f2zbWvOTfLlJFd192NV9Wf7NC8AAKzNMleWr0hysrsf6e5nktye5Nodaz6U5I7ufixJuvvJ1Y4JAADrt0wsn5/k8W3Hp7bObfemJK+tqu9V1f1V9dFVDQgAAAdl19swktSCc73gfd6e5P1JXp7kh1V1b3f//P+9UdXRJEeT5KKLLnrh0wIAwBotc2X5VJILtx1fkOSJBWu+292/7e6nk/wgyeU736i7j3f3RndvHDlyZK8zAwDAWiwTy/cluaSqLq6qc5Jcl+TOHWu+leQ9VXW4ql6R5J1JHlrtqAAAsF673obR3aer6qYkdyc5lOTW7n6wqm7cev1Ydz9UVd9N8kCS55J8tbt/up+DAwDAfqvunbcfr8fGxkafOHHiQL43AAAvHVV1f3dv7OVrPcEPAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABkvFclVdVVUPV9XJqrr5eda9o6qeraoPrm5EAAA4GLvGclUdSnJLkquTXJbk+qq6bFj3uSR3r3pIAAA4CMtcWb4iycnufqS7n0lye5JrF6z7RJJvJHlyhfMBAMCBWSaWz0/y+LbjU1vn/k9VnZ/k75McW91oAABwsJaJ5VpwrnccfyHJp7r72ed9o6qjVXWiqk489dRTS44IAAAH4/ASa04luXDb8QVJntixZiPJ7VWVJOcluaaqTnf3N7cv6u7jSY4nycbGxs7gBgCAM8oysXxfkkuq6uIk/5XkuiQf2r6guy/+/e+r6rYk/7ozlAEA4I/NrrHc3aer6qZsfsrFoSS3dveDVXXj1uvuUwYA4Ky0zJXldPddSe7acW5hJHf3P774sQAA4OB5gh8AAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMlorlqrqqqh6uqpNVdfOC1z9cVQ9s/bqnqi5f/agAALBeu8ZyVR1KckuSq5NcluT6qrpsx7JHk7y3u9+a5LNJjq96UAAAWLdlrixfkeRkdz/S3c8kuT3JtdsXdPc93f3rrcN7k1yw2jEBAGD9lonl85M8vu341Na5yceSfOfFDAUAAGeCw0usqQXneuHCqvdlM5bfPbx+NMnRJLnooouWHBEAAA7GMleWTyW5cNvxBUme2Lmoqt6a5KtJru3uXy56o+4+3t0b3b1x5MiRvcwLAABrs0ws35fkkqq6uKrOSXJdkju3L6iqi5LckeQj3f3z1Y8JAADrt+ttGN19uqpuSnJ3kkNJbu3uB6vqxq3XjyX5dJLXJflyVSXJ6e7e2L+xAQBg/1X3wtuP993GxkafOHHiQL43AAAvHVV1/14v5HqCHwAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAyWiuWquqqqHq6qk1V184LXq6q+uPX6A1X1ttWPCgAA67VrLFfVoSS3JLk6yWVJrq+qy3YsuzrJJVu/jib5yornBACAtVvmyvIVSU529yPd/UyS25Ncu2PNtUm+1pvuTXJuVb1hxbMCAMBaLRPL5yd5fNvxqa1zL3QNAAD8UTm8xJpacK73sCZVdTSbt2kkyf9U1U+X+P68tJyX5OmDHoIzjn3BIvYFi9gXLPLmvX7hMrF8KsmF244vSPLEHtaku48nOZ4kVXWiuzde0LSc9ewLFrEvWMS+YBH7gkWq6sRev3aZ2zDuS3JJVV1cVeckuS7JnTvW3Jnko1ufivGuJL/p7l/sdSgAADgT7HplubtPV9VNSe5OcijJrd39YFXduPX6sSR3Jbkmyckkv0tyw/6NDAAA67HMbRjp7ruyGcTbzx3b9vtO8vEX+L2Pv8D1vDTYFyxiX7CIfcEi9gWL7Hlf1GbnAgAAO3ncNQAADPY9lj0qm0WW2Bcf3toPD1TVPVV1+UHMyXrtti+2rXtHVT1bVR9c53wcjGX2RVVdWVU/qqoHq+r7656R9Vvi75HXVNW3q+rHW/vC/6c6y1XVrVX15PTRxHttzn2NZY/KZpEl98WjSd7b3W9N8tm4B+2st+S++P26z2XzPx1zlltmX1TVuUm+nOTvuvsvk/zDuudkvZb88+LjSX7W3ZcnuTLJ57c+1Yuz121Jrnqe1/fUnPt9Zdmjsllk133R3fd096+3Du/N5md3c3Zb5s+LJPlEkm8keXKdw3FgltkXH0pyR3c/liTdbW+c/ZbZF53k1VVVSV6V5FdJTq93TNapu3+QzZ/zZE/Nud+x7FHZLPJCf+YfS/KdfZ2IM8Gu+6Kqzk/y90mOhZeKZf68eFOS11bV96rq/qr66Nqm46Assy++lOQt2XxI2k+SfLK7n1vPeJyh9tScS3103Iuwskdlc1ZZ+mdeVe/LZiy/e18n4kywzL74QpJPdfezmxeLeAlYZl8cTvL2JO9P8vIkP6yqe7v75/s9HAdmmX3xgSQ/SvLXSf4iyb9V1b9393/v82ycufbUnPsdyyt7VDZnlaV+5lX11iRfTXJ1d/9yTbNxcJbZFxtJbt8K5fOSXFNVp7v7m2uZkIOw7N8jT3f3b5P8tqp+kOTyJGL57LXMvrghyT9vPQviZFU9muTSJP+xnhE5A+2pOff7NgyPymaRXfdFVV2U5I4kH3F16CVj133R3Rd39xu7+41J/iXJPwnls94yf498K8l7qupwVb0iyTuTPLTmOVmvZfbFY9n814ZU1euTvDnJI2udkjPNnppzX68se1Q2iyy5Lz6d5HVJvrx1FfF0d28c1MzsvyX3BS8xy+yL7n6oqr6b5IEkzyX5ancv/Ogozg5L/nnx2SS3VdVPsvnP75/q7qcPbGj2XVV9PZuffHJeVZ1K8pkkL0teXHN6gh8AAAw8wQ8AAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABv8L1jbGh/J+FgcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (range(0, 99))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x, loss_list, 'go--', linewidth=2, markersize=12, color='purple')\n",
    "plt.xlabel('Epoch', fontsize=22, color='white')\n",
    "plt.ylabel('Loss', fontsize=22, color='white')\n",
    "plt.gcf().set_facecolor(\"purple\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([4000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([4000, 32, 4, 4])\n",
      "Final layer:  torch.Size([4000, 10])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-e2dd36c24ddf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy: {accuracy_score(predicted, y_test)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    y_test = y_test_tensor.cpu().numpy()\n",
    "    predicted = predicted.cpu()\n",
    "    \n",
    "    accuracy_cnn = accuracy_score(predicted, y_test)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy_score(predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared models\n",
    "print(f'Accuracy of LogisticRegression: {accuracy*100}%')\n",
    "print(f'Accuracy of CNN/PyTorch: {accuracy_cnn*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
