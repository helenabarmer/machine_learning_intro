{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification \n",
    "\n",
    "* Dataset: [Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "* **Images**: Matrix of numbers (pixels). Each pixel holds a number we will work with\n",
    "* **Images with colors**: Multi channel. 3 values needed.\n",
    "* **Greyscale images**: Single channel images. 1 value needed.\n",
    "* Every image is 28x28 pixels.\n",
    "\n",
    "# 4 values\n",
    "\n",
    "* **List of images**: (1, 2, 3, 4)\n",
    "* **Value 1**: Number of images in the list\n",
    "* **Value 2,3**: Height and width of the image\n",
    "* **Value 4**: Number of channels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "#data = 'mnist.csv'\n",
    "data = 'https://raw.githubusercontent.com/helenabarmer/machine_learning_intro/master/Multiclass%20Classification/mnist.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df[df.columns[1:]]\n",
    "\n",
    "# Labels\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>2.321200</td>\n",
       "      <td>5.457800</td>\n",
       "      <td>...</td>\n",
       "      <td>34.320800</td>\n",
       "      <td>23.071900</td>\n",
       "      <td>16.432000</td>\n",
       "      <td>17.870600</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>17.790200</td>\n",
       "      <td>8.353500</td>\n",
       "      <td>2.541600</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.06560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.525187</td>\n",
       "      <td>2.494315</td>\n",
       "      <td>2.208882</td>\n",
       "      <td>4.669183</td>\n",
       "      <td>5.657849</td>\n",
       "      <td>8.591731</td>\n",
       "      <td>15.031508</td>\n",
       "      <td>23.359019</td>\n",
       "      <td>...</td>\n",
       "      <td>57.888679</td>\n",
       "      <td>49.049749</td>\n",
       "      <td>42.159665</td>\n",
       "      <td>44.140552</td>\n",
       "      <td>51.706601</td>\n",
       "      <td>45.128107</td>\n",
       "      <td>28.765769</td>\n",
       "      <td>16.417363</td>\n",
       "      <td>7.462533</td>\n",
       "      <td>1.93403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>107.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.000400      0.010300      0.052100      0.077000   \n",
       "std        2.872425      0.024493      0.525187      2.494315      2.208882   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000      2.000000     45.000000    218.000000    185.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.208600      0.349200      0.826700      2.321200      5.457800   \n",
       "std        4.669183      5.657849      8.591731     15.031508     23.359019   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    223.000000    247.000000    218.000000    244.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     34.320800     23.071900     16.432000     17.870600   \n",
       "std    ...     57.888679     49.049749     42.159665     44.140552   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     55.000000      6.000000      0.000000      0.000000   \n",
       "max    ...    254.000000    252.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      22.860000     17.790200      8.353500      2.541600      0.629500   \n",
       "std       51.706601     45.128107     28.765769     16.417363      7.462533   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    240.000000    225.000000    205.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  10000.00000  \n",
       "mean       0.06560  \n",
       "std        1.93403  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      107.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us scale our data as we can see the variance of the mean.\n",
    "Let's scale the pictures so they are at a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fit_scaler = scaler.fit(X)\n",
    "scaled_pixels = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def display_image(features, image_label):\n",
    "\n",
    "    # Labels\n",
    "    label_names = {\n",
    "        0: 'T-shirt',\n",
    "        1: 'Trouser',\n",
    "        2: 'Pullover',\n",
    "        3: 'Dress',\n",
    "        4: 'Coat',\n",
    "        5: 'Sandal',\n",
    "        6: 'Shirt',\n",
    "        7: 'Sneaker',\n",
    "        8: 'Bag',\n",
    "        9: 'Ankle boot'\n",
    "    }\n",
    "    \n",
    "    print('This is a', label_names[image_label].lower())\n",
    "    plt.imshow(features.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test to display image\n",
    "display_image(X.loc[5].values, y.loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our data\n",
    "We will go ahead and split our data into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Helena\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='sag', multi_class='auto', max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 78.325%\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict, normalize=True)\n",
    "print(f'Accuracy of model: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network comparision\n",
    "CNN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 784])\n",
      "X_test:  torch.Size([4000, 784])\n",
      "y_train:  torch.Size([6000])\n",
      "y_test:  torch.Size([4000])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float)\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float)\n",
    "print(\"X_test: \", X_test_tensor.shape)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "print(\"y_train: \", y_train_tensor.shape)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "print(\"y_test: \", y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape images to 1, 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 1, 28, 28])\n",
      "X_test:  torch.Size([4000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.Tensor(X_train_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "X_test_tensor = torch.Tensor(X_test_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "print(\"X_test: \", X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check number of labels: 10\n"
     ]
    }
   ],
   "source": [
    "# Input size, for grayscale 1 and for color 3\n",
    "input_size = 1\n",
    "\n",
    "# Hidden layers\n",
    "hidden_1 = 1\n",
    "hidden_2 = 32\n",
    "\n",
    "# Output values, we have 10 different labels\n",
    "print(f'Check number of labels: {len(df[\"label\"].unique())}')\n",
    "output = 10\n",
    "      \n",
    "nn_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_1, nn_size),\n",
    "            nn.BatchNorm2d(hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_2, nn_size),\n",
    "            nn.BatchNorm2d(hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Final layer\n",
    "        self.final_layer = nn.Linear(512, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer_1(x)\n",
    "        print(\"Layer 1: \", out.shape)\n",
    "\n",
    "        out = self.layer_2(out)\n",
    "        print(\"Layer 2: \", out.shape)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.final_layer(out)\n",
    "        print(\"Final layer: \", out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to cuda\n",
    "model = CNN_Model()\n",
    "model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move X and y to cuda\n",
    "X_train_tensor = X_train_tensor.to(cuda)\n",
    "X_test_tensor = X_test_tensor.to(cuda)\n",
    "\n",
    "y_train_tensor = y_train_tensor.to(cuda)\n",
    "y_test_tensor = y_test_tensor.to(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 1 Loss 0.5122336745262146\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 2 Loss 0.5102289915084839\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 3 Loss 0.508249044418335\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 4 Loss 0.506294846534729\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 5 Loss 0.5043638348579407\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 6 Loss 0.5024544596672058\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 7 Loss 0.5005643963813782\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 8 Loss 0.49869275093078613\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 9 Loss 0.4968380928039551\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 10 Loss 0.49500417709350586\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 11 Loss 0.4931865632534027\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 12 Loss 0.4913816750049591\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 13 Loss 0.48959264159202576\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 14 Loss 0.4878191649913788\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 15 Loss 0.48606348037719727\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 16 Loss 0.48432686924934387\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 17 Loss 0.482604444026947\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 18 Loss 0.48089730739593506\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 19 Loss 0.47920331358909607\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 20 Loss 0.47752371430397034\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 21 Loss 0.47586071491241455\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 22 Loss 0.47421374917030334\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 23 Loss 0.47258198261260986\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 24 Loss 0.4709624946117401\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 25 Loss 0.46935832500457764\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 26 Loss 0.4677671194076538\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 27 Loss 0.4661887586116791\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 28 Loss 0.46462276577949524\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 29 Loss 0.4630710482597351\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 30 Loss 0.4615322947502136\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 31 Loss 0.46000468730926514\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 32 Loss 0.45848900079727173\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 33 Loss 0.45698633790016174\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 34 Loss 0.45549750328063965\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 35 Loss 0.4540215730667114\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 36 Loss 0.45255643129348755\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 37 Loss 0.4511019289493561\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 38 Loss 0.4496583342552185\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 39 Loss 0.44822433590888977\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 40 Loss 0.44680073857307434\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 41 Loss 0.44538944959640503\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 42 Loss 0.4439903497695923\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 43 Loss 0.44260159134864807\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 44 Loss 0.441223680973053\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 45 Loss 0.43985649943351746\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 46 Loss 0.43849846720695496\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 47 Loss 0.4371481239795685\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 48 Loss 0.43580639362335205\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 49 Loss 0.43447229266166687\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 50 Loss 0.43314531445503235\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 51 Loss 0.4318273961544037\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 52 Loss 0.4305194616317749\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 53 Loss 0.4292202293872833\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 54 Loss 0.42792749404907227\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 55 Loss 0.42664217948913574\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Loss 0.42536357045173645\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 57 Loss 0.4240924119949341\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 58 Loss 0.42282792925834656\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 59 Loss 0.4215727150440216\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 60 Loss 0.42032742500305176\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 61 Loss 0.4190911054611206\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 62 Loss 0.41786253452301025\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 63 Loss 0.4166417717933655\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 64 Loss 0.4154285192489624\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 65 Loss 0.4142242968082428\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 66 Loss 0.4130280315876007\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 67 Loss 0.4118386209011078\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 68 Loss 0.41065648198127747\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 69 Loss 0.40948227047920227\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 70 Loss 0.40831640362739563\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 71 Loss 0.407155305147171\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 72 Loss 0.4060019254684448\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 73 Loss 0.4048556685447693\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 74 Loss 0.4037160575389862\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 75 Loss 0.4025808870792389\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 76 Loss 0.40145134925842285\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 77 Loss 0.4003276228904724\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 78 Loss 0.39920932054519653\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 79 Loss 0.3980957567691803\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 80 Loss 0.39698705077171326\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 81 Loss 0.39588281512260437\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 82 Loss 0.39478442072868347\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 83 Loss 0.3936917185783386\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 84 Loss 0.3926066756248474\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 85 Loss 0.3915274739265442\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 86 Loss 0.39045435190200806\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 87 Loss 0.38938722014427185\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 88 Loss 0.3883250653743744\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 89 Loss 0.3872684836387634\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 90 Loss 0.386217325925827\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 91 Loss 0.38516974449157715\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 92 Loss 0.3841286897659302\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 93 Loss 0.3830929696559906\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 94 Loss 0.3820629119873047\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 95 Loss 0.38103803992271423\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 96 Loss 0.38001981377601624\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 97 Loss 0.37900662422180176\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 98 Loss 0.3779992163181305\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 99 Loss 0.37699776887893677\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_list = list()\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    # Calculate output and loss\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Zero out gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pas\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch} Loss {loss.item()}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAHqCAYAAACqb5DMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6EUlEQVR4nO3df3TV9Z3v++dOsoWQJoAVLIkiFCGSUpWfVtTaVuvxx1gpoLNWrdIZPaU9TufQq2s54109B9uzuGfutben0zlnjiOeafGOY0UFZcrQccZatSAQrfaEmrCrgCSxRREJhoB7Z+/7R9iRhERI8v1+96/nY/9j9v7uvT/pd1XffHi935/YSlZmkCRJkhSZslwvQJIkSSo1FuGSJElSxCzCJUmSpIhZhEuSJEkRswiXJEmSImYRLkmSJEWsItcLyIUfffxHTJkyJdfLkCRJUhH77Uu/5W7uHvC1kizCp0yZQmNjY66XIUmSpCJWG6sd9DXjKJIkSVLELMIlSZKkiFmES5IkSRGzCJckSZIiZhEuSZIkRcwiXJIkSYqYRbgkSZIUMYtwSZIkKWIW4ZIkSVLELMIlSZKkiFmES5IkSRGzCJckSZIiVpHrBRSzTCZD27Y2tty3hcTGBMmuJPHKONOvm87CuxZSO7+WWCyW62VKkiQpYhbhIelOdrP+1vW0PNVC6kiKTDoDQPJwktcef43ExgT119ezaM0iyuPlOV6tJEmSomQcJQSZTKa3AE8eTvYW4L2vpzMkO5M0P9nM+lvXk8lkBvkkSZIkFSOL8BC0bWujZUNPAf5RUl0pWja00L69PaKVSZIkKR9YhIdgy/e3kOpKndK1qa4UW76/JeQVSZIkKZ9YhIcg8bPECRGUwWTSGXb+bGfIK5IkSVI+sQgPQbLro2MoJ1zfmWRV1SrW3rSWtm1tZsQlSZKKnEV4COKV8SG/Jzs15Sdf+AlPfOUJupPdIaxMkiRJ+cAiPATTr5tOrGzo87+dmiJJklQaLMJDcPGdF1NROfwR7E5NkSRJKm4W4SGoW1BH/fX1Iy7EnZoiSZJUnCzCQxCLxVi0ZhHn3XAe8ar4sKMpOx7dYcOmJElSEbIID0l5vJzFDy9m2TPLmLlkJvGqoTdrgg2bkiRJxcgiPESxWIy6BXXc+OiN3PP+PcTHDK8Qt2FTkiSpuFiER2i4U1OybNiUJEkqDhbhERrp1BSwYVOSJKkYWIRHKIipKR5zL0mSVPgswiMUxNQU6Dnm/t6ye52cIkmSVKAswiMW1NQUMk5OkSRJKlQW4TnQf2pKw40Nw94Vd3KKJElS4bEIzwNBNWw6OUWSJKkwWITngSAaNsHJKZIkSYXCIjwPBNWw6eQUSZKkwmARnicGatgcTjGe7Ew6NUWSJCnPjSz/oEAd37CZtapqFcnDySF9TnZqSmJjgvrr61m0ZhHl8fKglytJkqRhcic8zw33qHunpkiSJOUvi/A8N9LJKU5NkSRJyj8W4XkuiMkpTk2RJEnKLxbheS6IySmZdIYdj+6wYVOSJClPWIQXgKCOuveYe0mSpPxgEV4g+h91Hx8zvELchk1JkqTcswgvUMOdmpJlw6YkSVLuWIQXqJFOTQEbNiVJknLFIrxABTE1xWPuJUmScsMivEAFMTUFPOZekiQpFyzCC5hTUyRJkgqTRXiB6z81peHGBo+5lyRJynMW4UXGY+4lSZLy38jGawQkQYJNbCJNmjnM4TIu6/P6LnbxCI8wjnEAzGQmn+Nzp/TeUpNt2Gx+splUV2pYn5GdmrL0p0sDXp0kSZIgD4rwNGk2spFbuIUaaniAB6innolM7HPdZCZzMzcP672lJNuwuf7W9bRsaCHVlSKTHlq0JHvM/c5/2sn066az8K6F1M6vJRYb/lxySZIkfSjncZQ22jj92KOCCmYxixZaQn9vMbNhU5IkKb/lfCe8gw5qqOn9uYYaWmk94bpWWvlb/pZqqrmKq5jIxFN+L0AjjbzESwDE3x5eUVpIjm/YBFhVtYrk4eSQP6d/w+bihxe7Iy5JkjRCOd8JH0iMvkXeJCaxghV8k2+ygAU8wiOn/N6secxj+bHHhAkTAl1vIfCYe0mSpPyR8yK8hho66Oj9uYMOqqnuc81oRjOKUQDMYAbddNNJ5ym9Vz085l6SJCl/5LwIr6WW/eznAAdIkaKJJuqp73PNIQ6Roae5sJVWMmQYw5hTeq96eMy9JElS/sh5Jryccq7lWh7iITJkmM1sJjKR7WwHYD7z+S2/pZFGyiijggqWspQYsUHfqxMFMTUFeo65v7fsXuKVcSenSJIkDVNsJStL7mjEDXM30NjYmOtl5EQmk6F9ezub79tMYmOCZOfQmzWzYmUxKiorqL++nkVrFlEeLw9wpZIkSYWtNlbLcpYP+FrO4yiKVlDH3INH3UuSJA2XRXiJC6ph08kpkiRJp84ivMQF0bAJTk6RJEkaCovwEpdt2DzvhvOIV8VHFE3Z8egOVlWtYu1Na2nb1mY8RZIkaRAW4RrwmPvhFuMedS9JknRyOR9RqPzQ/5h78Kh7SZKksLgTrkF51L0kSVI4LMI1KI+6lyRJCodFuAYV1FH3NmxKkiT1ZRGuQQU1OQVs2JQkSTqeRbg+0kCTU4bLEzYlSZJ6WITrpII86h5s2JQkSbII15DZsClJkjQyFuEasqAaNnf+bGeAq5IkSSocFuEasqAaNpOdSaemSJKkkmQRrmEJqmHTqSmSJKkUWYRr2IJq2HRqiiRJKjUW4QrMSBs2nZoiSZJKhUW4AhNEw6ZTUyRJUimwCFdggmjYzB5zf2/ZvTZtSpKkomURrkAFdsJmxqZNSZJUvCzCFbj+DZvxMR51L0mSdDyLcIVu+nXTR3TMPdi0KUmSiotFuEIXxDH3YNOmJEkqHhbhCl0QU1Pgw6ZNGzYlSVKhswhX6II65j7Lhk1JklToLMIViYGmpoykGLdhU5IkFbKRB3WlU3T81JSstTet5bXHXyOTHl4RfXzDZt2CuqCWKkmSFCp3wpVTQTRt2rApSZIKjUW4ciqIpk0bNiVJUqGxCFdOBdm0acOmJEkqFBbhyrnAjrrHhk1JklQYLMKVF/ofdd9wY8OIdsU9YVOSJOUzi3DlJRs2JUlSMbMIV16yYVOSJBUzi3DlJRs2JUlSMbMIV96yYVOSJBUri3DlNRs2JUlSMbIIV0GxYVOSJBUDi3AVFBs2JUlSMbAIV0GxYVOSJBUDi3AVHBs2JUlSobMIV0GyYVOSJBUyi3AVBRs2JUlSIRlZ1SLliWzDZvOTzaS6UsP6jGzD5o61O4hXxpl+3XQW3rWQ2vm1xGLD32WXJEnqz51wFYUgGzbJ2LQpSZLCZRGuohFkwybYtClJksJjEa6iEnTDJti0KUmSgmcRrqIWRMMm2LQpSZKClReNmQkSbGITadLMYQ6XcdmA17XRxmpWs5SlfIpPAbCFLbzMywCcyZncwA3EGVkMQcUjiIZN+LBpc+c/7bRhU5IkjVjOd8LTpNnIRm7mZu7gDppoYh/7BrzuaZ5mGtN6n+ugg61s5et8nTu4gzRpmmiKcvnKc4E2bGLDpiRJCkbOi/A22jj92KOCCmYxixZaTrhuK1tpoIEqqvo8nyZNkiTddJMkSTXVUS1dBWKghs2RFOM2bEqSpJHKeRylgw5qqOn9uYYaWmk94ZpmmlnGMtpo63PtQhbyA35AnDjTmMa5nBvZ2lU4jm/YzFp701pee/w1MunhFdHHN2zWLagLaqmSJKkE5HwnfCAx+u5SbmITV3IlZf2W20UXzTSzghXcyZ18wAe8yqsDfmYjjdx/7PH222+HtnYVDk/ZlCRJuZLznfAaauigo/fnDjpOiJS0085jPAbAYQ6TIEEZZaRJM57xvRGVmcxkL3u5gAtO+J55xx4AGyZsCOvXUQEJ8pRNGzYlSdJQ5LwIr6WW/eznAAeoppommljCkj7XrGBF7z+vYx0zmMFMZtJ67PEBHxAnzi52UUttxL+BClW2aXP9retp2dBCqis17GhKtmEzsTFB/fX1LFqziPJ4ecArliRJxSLnRXg55VzLtTzEQ2TIMJvZTGQi29kOwHzmD/resziLBhq4n/spo4xJTGIuc6NauopAtmmzfXs7m+/bTGJjgmRnclif1b9hc/HDi90RlyRJA4qtZGXJjXbYMHcDjY2NuV6G8tRIGzYB4lVxlj2zzIZNSZJKWG2sluUsH/C1vGzMlHLJhk1JkhQ2i3Cpn2zD5kgK8WzD5qqqVay9aS1t29qcJy5JknpZhEv9BHnKpidsSpKkgViESwMY6JTN4fKETUmS1J9FuDSI40/ZvOf9e2i4sWFEu+LHn7ApSZJKm0W4dIps2JQkSUGxCJdOkQ2bkiQpKBbh0imyYVOSJAXFIlwaAhs2JUlSECzCpSGyYVOSJI2URbg0QjZsSpKkoRpZ5SCpt2Gz+clmUl2pYX1GtmFzx9odxCvjTL9uOgvvWkjt/FpiseHvskuSpPzkTrg0QkE2bJKxaVOSpFJgES4FIMiGTbBpU5KkYmcRLgUk6IZNsGlTkqRiZREuhSSIhk2AZGeS1Ret9oAfSZKKiEW4FJIgTtg8nllxSZKKh0W4FJJAGzaPMSsuSVJxsAiXQjRQw2YQxbhZcUmSCptzwqWQHd+wmbX2prW89vhrZNLD38nOHvCz9KdLg1imJEmKkDvhUg4E0bSZPeDHhk1JkgqPRbiUA0E2bdqwKUlS4bEIl3Ig6KZNGzYlSSosFuFSjgR9yibYsClJUqGwCJdyqP8pm7e9eNuIi/Fsw6YkScpfFuFSHgkiK27DpiRJ+c8iXMojQWbFbdiUJCl/WYRLeSbIrLgNm5Ik5SeLcCkP9c+KN9zYMKJdcRs2JUnKL56YKRWAi++8mMTGBMnO5LA/I9mZ5MGFD5JJZ4hXxpl+3XQW3rWQ2vm1xGIjG5EoSZKGxp1wqQAEdbhPpjsDGfPikiTlmkW4VACCPtwHzItLkpRLFuFSgQjjcB8wLy5JUi5YhEsFJOiGzSwP+JEkKVoW4VIBu/jOi0ecEwcP+JEkKWoW4VIBC6phM8uGTUmSomERLhUwGzYlSSpMFuFSgRuoYTNWFiNWPrKC3IZNSZLC42E9UhE4vmEzq3VrK2uuWDPiA35WX7Sa+BgP95EkKUjuhEtFKsi8uFlxSZKCZREuFamg8+JmxSVJCo5FuFTEwjjgx6y4JEkjZxEuFbkwDvjxcB9JkkbGIlwqMUEc8OPhPpIkjYxFuFRibNiUJCn3LMKlEmPDpiRJuWcRLpUgGzYlScotD+uRSlT/A3483EeSpOi4Ey4JMCsuSVKULMIlAWbFJUmKUl7EURIk2MQm0qSZwxwu47IBr2ujjdWsZilL+RSfAqCLLp7iKfaxjxgxbuAGzubsKJcvFY1sVrx9ezub79tMYmNiRPEU6JsVr1tQF9BKJUkqbDkvwtOk2chGbuEWaqjhAR6gnnomMvGE657maaYxrc/zm9jEuZzLH/PHpEiRZGQFg1Tq+mfF1960ltcef41Mevg72dnDfZb+dGlQy5QkqaDlPI7SRhunH3tUUMEsZtFCywnXbWUrDTRQRVXvc0c4wh72MIc5AFRQQSWVka1dKgVBHu5zb9m9HvAjSRJ5sBPeQQc11PT+XEMNrbSecE0zzSxjGW209T5/gAOMYQzrWc8f+AOTmMQ1XMNpnHbC9zTSyEu8BED87ZGPY5NKRbZhs/nJZlJdqZF9WObDps3ExgT119ezaM0iyuPlwSxWkqQCkfOd8IHE6NsQtolNXMmVlPVbbpo0b/EW85nPN/gGp3EaL/DCgJ85j3ksP/aYMGFCaGuXik3QDZtg06YkSTnfCa+hhg46en/uoINqqvtc0047j/EYAIc5TIIEZZRxFmdRQw1ncRYADTQMWoRLGr4wGjbBpk1JUunKeRFeSy372c8BDlBNNU00sYQlfa5ZwYref17HOmYwg5nMBGAsY3mHdziDM3iDN5iAu9xSGMI43Ac84EeSVJpyXoSXU861XMtDPESGDLOZzUQmsp3tAMxn/ke+/xqu4XEep5tuxjOeRSyKYNWSAs2KY1ZcklRaYitZWXJhzA1zN9DY2JjrZUgFrzvZzfpb19OyoYVUV2pEYwyPV1FZwXk3nMfihxe7Iy5JKli1sVqWs3zA1/KyMVNSYchmxZc9s4yZS2YG1rh5fFZckqRilPM4iqTC1j8rDh7wI0nSybgTLilwQR7w4+E+kqRiZBEuKXDZps2RFuLwYcPmT77wE574yhN0J7sDWKEkSbllES4pcEEf8OPhPpKkYmMRLikUAzVtjpQNm5KkYmFjpqTQhHHAj4f7SJKKgTvhkiJjVlySpB4W4ZIiY1ZckqQeFuGSImVWXJIkM+GScqB/VjyIw33MikuSCok74ZJyLojDfbLMikuSCoFFuKScC7JhE8yKS5Lyn0W4pJwLumEzy6y4JClfmQmXlBeyDZvt29vZfN9mEhsTI5onnpXsTPLgwgfJpDPEK82LS5Lyg0W4pLwRxuE+AJnunjhKNi+e2Jig/vp6Fq1ZRHm8fMTrliRpqIyjSMpbQWfFwby4JCk/WIRLylthZcXBvLgkKbcswiXltTAO98lKdaXY8v0tgX2eJEmnyky4pLwXWlY8nWHHozvY+U87bdiUJEUq0J3weFWcSXMmUTWxKsiPlaQ+gs6Ke8CPJClqQy7Cp3xuCtf+92v5xIWf6PP8Bcsu4K4/3MXt227n263f5vPf+3xgi5Sk44WRFbdhU5IUpSEX4bNvn83sP53Ne7vf631u3JRxXP931xOvjHOo7RAAl/7lpUz9wtTAFipJxxsoKx4rixErH1lBbsOmJCkKQ/673LoFdfz+1d9z5L0jvc+df8v5lFWU8a93/yub79vMpLmTuP3F25n3H+ax65ldgS5YkrL6Z8UhmLx4sjPJ6otWEx/j4T6SpHAMeSe8akIVHa0dfZ6b+oWppI6k2PY32wB466W32Lt5L5+44BMDfYQkhSbIvLhZcUlSWIZchMfHxEkn0x8+EYNJcyfRtq2N1JFU79MH9x7kY5M+FsgiJelUBZ0XNysuSQrDkIvwzn2dnD799N6fz/rMWZxWdRp7f7W3z3UVoypIdaX6v12SQhfGbHGz4pKkIA25CN+7ZS+fuPATNNzYwGnVp3HZ/3kZmUyG159+vc91Z8w8g0PthwJbqCQNxfF58Xvev4eGGxtGvCuezYqvqlrF2pvW0ratzZ1xSdKwDLkI3/z/bCadSrPkH5dw94G7mX7NdH7/yu/Z88s9vddU11UzYeYE2hvdMZKUHy6+82LnikuS8saQi/D27e384x/9I3t+uYd3XnuHV378Cg9f+3Cfa2b98SyOHDzCG0+/EdhCJWkkgj7gx6y4JGkkYitZWXL/5dgwdwONjY25XoakiHUnu1l/63paNrSQ6kqRSQfzr794VZxlzyyjbkFdIJ8nSSoOtbFalrN8wNeC2RKSpAKQbdhs397O5vs2k9iYGNE88SznikuShmrIRXhZvIzR40ZztOMo3Uc/zEHGq+Jc+heXcuYFZ3Jw90F+9X//6oR54pKUa/0P+AnicJ+sbFY8sTFB/fX1LFqziPJ4+Yg/V5JUfIacCb/8O5dz51t3Mmn2pA+fjMGfPPcnXPqXlzLjuhnMv2M+t225jcrTK4NcqyQFzqy4JCkXhlyET71iKofaDtH6YmvvczO/PJNPXPgJ9jXt46nbn+K1da9RXVvNvG/MC3SxkhS0oA/3yXKuuCTpowx562fclHHs27Gvz3P1N9STyWRY99V17Gvaxys/foVv7/025335PJ5f9Xxgi5WkMISZFX9w4YNk0hnilebFJUkfGnIRXnl6JZ1/6Ozz3NkLz+bgnoPsazpWnGegbWsbky+dHMgiJSlsYWXFM909cRTz4pKk4w05jtKd7GbU2FG9P4+ZMIbxnxzPmy+82ee65OEkp33stJGvUJJyIOisOJgXlyR9aMhF+P6d+5l8yWTKR/Xs4DQsaSCTyZxQhH9s0sfo3Nc50EdIUt4LKysO5sUlScMown+79reMHjeaP3nuT7jq+1dx5V9dSfcH3TSvb+69JlYWY9KcSbz7u3cDXawkRSmbFV/2zDJmLplJvCoe2GdnZ4uvqlrF2pvW0ratzZ1xSSohQ/571hd/8CKf/OInmfr5qdTOqyXdnebnK37O4bcP914z7appjB47mj3P7Ql0sZIUtTDnioNZcUkqVUMuwrs/6OahKx9i8qWTqTqzirdefov3dr3X55rUkRQ///bPaXmqJah1SlJeyGbFm59sJtWVCuQz+2fFFz+82OkpklTkht1x1D8Dfrzdz+5m97O7h/vRkpS3slnx9beup2VDC6muFJl0MDGS47PidQvqAvlMSVJ+CqTtv/LjPSdjdr3bBUYaJRW5geaKp7pSEPtwJOFwZbPi8THOFZekYjbsIvyTV36Si++6mMmXTqZidM/HpI6kePP5N9ny/S288a9vBLZISco3/bPiEGxe3Ky4JBW3IU9HAfjcys9x86abmfbFacQr4z273xmIV8aZdtU0bt50M5f/58sDXqok5begZ4s7V1ySiteQ/0sx7d9N47Pf+SzJw0m2/c02fv2/ft3bmDluyjhm/+ls5v/ZfD77nc/SuqWV1//l9aDXLEl5Kay8uFlxSSo+Q94JX/CtBaS70/zDtf/Av/3lv/Fu4l3SqTTpVJp3f/cu/3bPv/HwdQ9DpudaSSolYc0Wd664JBWXIe+E1y2oY++v9vLm84NPR3nz+TfZ8/we6i5yx0ZS6QlztrhZcUkqDkPeCR9VPYqO1o6TXneo/RCjqked0mcmSPAjfsQP+SHP8/yg17XRxr3cyw529Hk+TZr/yf/kH/iHU/o+SYqSWXFJUn9DLsI793Vy5vlnnvS6ibMm0vl250mvS5NmIxu5mZu5gztoool97Bvwuqd5mmlMO+G1F3mRMzjj1H4BSYpYNit+3g3nEa+KEysLZtzg8VlxSVJhGXIRvvvZ3Uz41AQu+vOLBr1mwZ8t4MxPn8muZ3ad9PPaaOP0Y48KKpjFLFo48aTNrWylgQaqqOrz/EEOkiDBHOYM9VeRpMiEmRV/cOGD3Ft2r3lxSSogQ/670Rf+6ws03NjAVf/vVcxcMpNXf/IqB3YdgAyM/+R4zr/1fCZfOpnUkRS/+qtfnfTzOuighpren2uooZXWE65pppllLKONtj6vbWITX+SLHOXoUH8VSYpUWFnx7AFB5sUlqXAMuQh/57V3eOyPH+PLD32ZyZdO5uxLzu7zeiwW4+iho6y7ZR3vvPbOsBYVo+9f1W5iE1dyJWX9Nu5baKGKKmqpZRcfveveSCMv8RIA8beD2YGSpJHIZsWbn2zuOXEzAP3z4osfXuxpm5KUh4bVJbRzw07+ZsbfMPfrc5n82cnU1NVADDpaO9jzyz28/MDLANScXUPH3o9u4qyhhg4+vKaDDqqp7nNNO+08xmMAHOYwCRKUUUYbbbTQQoIEKVIc5SiP8zhLWHLC98w79gDYMGHDcH5tSQpUWHPFwdnikpTvht2q37mvk+f+y3ODvv6nm/+Uuvl1fC/+vY/8nFpq2c9+DnCAaqppoumEInoFK3r/eR3rmMEMZh57XMmVAOxiF5vZPGABLkn5KpsVb9/ezub7NpPYmAhklCF8OFs8PibO9Oums/CuhdTOr3VnXJLyQDDzsgZzCv+eL6eca7mWh3iIDBlmM5uJTGQ72wGYz/xQlyhJuRbmXHEwKy5J+SjcIvwUzTj2ON5gxfeX+fKAz0899pCkQmdWXJKK35BHFEqSwhXWXHFwtrgk5Yu82AmXJPU1UFY81ZWC2IcjCYfLrLgk5Z5FuCTlqf5ZcQg2L25WXJJyxziKJBWQbF68ojKYPZT+WXFP2pSkaJz03+KTL5s8rA8eVTNqWO+TJA0urNnizhWXpGidtAj/2rNfG9bOSCwWc0dFkkIQ1mxxs+KSFJ2TFuEH3zxoMS1JeSbM2eJmxSUpfCctwn849YdRrEOSNAJBzxZ3rrgkhcvGTEkqAmHNFneuuCSFwxGFklQkzIpLUuGwCJekImJWXJIKg3EUSSpizhWXpPxkES5JRcysuCTlJ+MoklTkwsyKP7jwQTLpDPFK8+KSNBQW4ZJUAsLKime6e+Io5sUlaWiMo0hSCQo6Kw7mxSVpKCzCJakEhZUVB/PiknQqjKNIUokKKysOzhaXpJOxCJekEhbmXHEwKy5JgzGOIknqZVZckqJhES5J6hV2VrzpkSa+W/5dVlWtYu1Na2nb1mZRLqkkWYRLkvrIZsWXPbOMmUtm9hbjsfKACvLMhzGVn3zhJzzxlSfoTnYH89mSVCDMhEuSTtA/Kw7B58X7x1QWP7zYxk1JJcOdcEnSKQkjLw6ONJRUmizCJUmnJMy8eHakoVlxSaXCIlySdMoGyosHyay4pFJhES5JGpLj8+L3vH8Pt714W6DFuCMNJZUCi3BJ0oiYFZekobMIlySNiFlxSRo6i3BJ0ogNmBUPcNqgWXFJxcY54ZKkQPSfLZ7JZHjiK0/Q/GQzqa7UiD/fueKSiok74ZKkUIQVUzErLqkYuBMuSQpNNqbSvr2dzfdtJrExEciJm8nOJA8ufJBMOkO8Ms7066az8K6F1M6vdXdcUkGwCJckhap/TKV1aytrrlgz4mI8093ToJnNiyc2Jqi/vp5FaxZRHi8f8bolKUzGUSRJkQpjpKGzxSUVGotwSVKkwhxpmOpK0fRIE98t/65jDSXlNYtwSVLkBhxpGKSMYw0l5TeLcElSThyfFb/n/Xu47cXbAi/GjalIylcW4ZKkvBBGVjzLsYaS8o1FuCQpL4SZFYeesYarL1ptVlxSXrAIlyTljYGy4rGyGLHy4Apys+KS8oFzwiVJeaX/XHEIbrZ4Vv+s+OKHF3vIj6RIuRMuScp7YeXFzYpLyhWLcElS3gszL25WXFIuWIRLkgrCgLPFA0yQmBWXFCUz4ZKkgtE/L57JZHjiK0/Q/GQzqa7UiD/frLikqLgTLkkqWGHFVFJdKZoeaeK75d81piIpFBbhkqSCNmBMJSgZYyqSwmERLkkqeMfHVO55/x5ue/G2QIvx/jEVd8QljZRFuCSp6DjSUFK+y4vGzAQJNrGJNGnmMIfLuGzA69poYzWrWcpSPsWnOMhB1rGO93mfGDHmMpfP8JmIVy9JyjfZrPj6W9fTsqGFVFeKTDqY3etkZ5IHFz5IJp0hXhln+nXTWXjXQmrn19rEKemU5bwIT5NmIxu5hVuooYYHeIB66pnIxBOue5qnmca03ufKKOMqrqKWWo5ylPu5n0/yyRPeK0kqPdmsePv2djbft5nExkRwJ2529xT02bx4YmOC+uvrWbRmEeXx8kC+Q1Jxy3kcpY02Tj/2qKCCWcyihZYTrtvKVhpooIqq3ueqqaaWWgBGMYoJTOAQhyJbuyQpv4WdFQfz4pKGJ+dFeAcd1FDT+3MNNXTQccI1zTQzj3mDfs4BDvAWb1FH3YCvN9LI/cceb7/9djCLlyQVlLCy4mBeXNLQ5DyOMpBYvyPQNrGJK7mSskH+zHCUozzKo1zN1Yxm9IDXzDv2ANgwYUOwC5YkFYQws+LQkxdffdFq4mPMikv6aDkvwvvvfHfQQTXVfa5pp53HeAyAwxwmQYIyypjJTLrp5lEe5dN8mgYaIl27JKnwDJgVP5yEAFMkZsUlnUzOi/BaatnPfg5wgGqqaaKJJSzpc80KVvT+8zrWMYMZzGQmGTI8yZOcwRksZGHEK5ckFarjs+IAmUyGJ77yBM1PNpPqSgXyHf2z4osfXuyOuKReOS/CyynnWq7lIR4iQ4bZzGYiE9nOdgDmM3/Q977Jm/yG3zCRifwtfwvAFVzBDGZEsnZJUnEIM6aS6krR9EgTTT9tcqShpF6xlawsuTbuDXM30NjYmOtlSJLyTCaT6RNTSXWlIPbhSMIgxMpiVFRWGFORSkBtrJblLB/wtZzvhEuSlC/6x1QAWre2suaKNcHNGDemIok8GFEoSVI+C2usoSMNpdJmES5J0kfI5sXPu+E84lVxYmXB7VpnRxquqlrF2pvW0ratzcN+pBJhES5J0klkxxoue2YZM5fMDPzUzexIw5984Sc88ZUn6E52B/r5kvKPRbgkSafg+Lz4Pe/fw20v3hZoMd4/K+6OuFTcbMyUJGkYslnxIGeLQ09WfMfaHTSvbyZ1NOVYQ6lIuRMuSdIwhJkVz3RnSB1JQcaoilSsLMIlSRqmAbPiIWxUG1WRio9xFEmSRqD/bPFMJsMTX3ki8JgK9B1rWLegLtDPlhQtd8IlSQpQmDEVcKyhVCwswiVJCljYIw3BrLhU6CzCJUkKQdgjDcGsuFTIzIRLkhSBsEYaQk9WvOmRJpp+2uRIQ6lAuBMuSVIEws6KA440lAqIRbgkSREZKCseK4tRPrqcWHmAc8aNqUh5zziKJEkR6j/SEMIba+hIQyl/uRMuSVKOhRlVcaShlJ8swiVJygNhjzU0Ky7lF4twSZLyRNhjDc2KS/nDTLgkSXkqrLGGjjSUcs+dcEmS8lToYw0daSjljEW4JEl5bMCseNC1uDEVKXLGUSRJynP9xxqGOdJwx9odNK9vJnU0ZVRFCpE74ZIkFZgwYyqZ7gypIymjKlLILMIlSSpAYY80zDKqIoXDOIokSQWqf0yldWsra65YQ7IzGfh3efqmFCx3wiVJKhLZkYYVleHssXn6phQci3BJkopE6CMNjzErLo2cRbgkSUUkipGGYFZcGikz4ZIkFZmoRhqCp29Kw+VOuCRJRS6SmIojDaUhsQiXJKkEDBRTiZXFKB9dTqw8wDnjxlSkU2IcRZKkEtE/pgLhnr7pSENpcO6ES5JUwsKMqjjSUBqcRbgkSSUu7NM3zYpLJ7IIlyRJfaIq97x/D7e9eFugxbhZcakvM+GSJOkE2dM3w8iKO9JQcidckiQNIPSxho40VImzCJckSQOK4vRNYyoqVcZRJEnSoKI6fTPVlWLH2h00r28mdTRlVEVFz51wSZJ0ysKMqWS6M6SOpIyqqCRYhEuSpCEJe6RhllEVFTPjKJIkacj6x1Rat7ay5oo1JDuTgX+Xp2+qGLkTLkmSRiw70rCiMpz9PU/fVLGxCJckSSMW+kjDY8yKq1hYhEuSpEBEMdIQzIqrOJgJlyRJgYlqpCF4+qYKmzvhkiQpNJHEVBxpqAJkES5JkkI1UEwlVhajfHQ5sfIA54wbU1EByYs4SoIEm9hEmjRzmMNlXDbgdW20sZrVLGUpn+JTQ3qvJEnKnf4xFQj39E1jKsp3Od8JT5NmIxu5mZu5gztoool97Bvwuqd5mmlMG/J7JUlS/gk9qmJMRXks50V4G22cfuxRQQWzmEULLSdct5WtNNBAFVVDfq8kScpPUZy+aUxF+SjncZQOOqihpvfnGmpopfWEa5ppZhnLaKNtSO+VJEn5LarTN1NdKXas3UHz+mZSR1NGVZRTOS/CBxLrN1R0E5u4kispO4WN+/7vzWqkkZd4CYD428H/KVuSJAUje/pmGGMNM90ZUt09n5mNqiQ2Jqi/vp5FaxZRHi8P9PukweS8CK+hhg46en/uoINqqvtc0047j/EYAIc5TIIEZZSd0nuz5h17AGyYsCHoX0OSJAUkmxVff+t6Wja0kOpKkUmHEyHpH1VZ/PBid8QViZwX4bXUsp/9HOAA1VTTRBNLWNLnmhWs6P3ndaxjBjOYyUy66T7peyVJUuHJZsXbt7ez+b7NJDYmSB5OQkhx7lRXipYNLbRvb6duQV04XyIdJ+dFeDnlXMu1PMRDZMgwm9lMZCLb2Q7AfOYP+b2SJKnwRXn6JkCyM8nqi1YTH2NWXOGLrWRlybUIb5i7gcbGxlwvQ5IkDVF3sjuSmEqsLEZFZYVZcY1IbayW5Swf8LWcjyiUJEk6VQOONAxho9qxhgpbzuMokiRJQxFlTMXTNxUWd8IlSVJBC/3kTfD0TQXOIlySJBW8gWIqsbIY5aPLiZUHV5QbU1FQjKNIkqSi0D+mAuFFVYypaKTcCZckSUUr9KiKMRUNk0W4JEkqagNOVAmYMRUNlXEUSZJU9PpHVVq3trLmijUkO5OBfo8xFZ0qd8IlSVLJqVtQR/319VRUhrQfaUxFJ2ERLkmSSk4kYw0xpqLBGUeRJEklKZsVb9/ezub7NpPYmCB5OAkh1MmprhQ71u6geX0zqaMpoyqyCJckSaUrytM3M90ZUt09n5mNqiQ2Jqi/vp5FaxZRHi8P9PuU34yjSJIkHRNVTAWMqpQ6i3BJkqTjDDjSMMS0SKorRcuGFtq3t4f3Jco7xlEkSZL6iTKmApDsTLL6otXEx5gVLxXuhEuSJJ1EVDEVxxqWDotwSZKkUxBVTMWseGkwjiJJknSKooypePpmcXMnXJIkaZgiial4+mZRsgiXJEkagYFiKrGyGOWjy4mVB1eUG1MpLsZRJEmSRqh/TAXCi6oYUykO7oRLkiSFIPSoijGVgmYRLkmSFJIBJ6oEzJhKYTKOIkmSFKL+UZXWra2suWINyc5koN9jTKWwuBMuSZIUoboFddRfX09FZUh7ocZUCoJFuCRJUoSiOn3TmEp+M44iSZIUsWxWvH17O5vv20xiY4Lk4SSEUCenulLsWLuD5vXNpI6mjKrkCYtwSZKkHIjy9M1Md4ZUd89nZqMqiY0J6q+vZ9GaRZTHywP9Pp2ccRRJkqQ8EFVMBYyq5AN3wiVJkvJElDEVcKJKLlmES5Ik5ZEoYyq9MsZUomYcRZIkKY8ZUylO7oRLkiTlOWMqxcciXJIkqQAYUykuxlEkSZIKkDGVwuZOuCRJUoEaKKaS6kpRdloZ6WSaTHewxbIxleBYhEuSJBWw/jEViCCqYkxlxIyjSJIkFZmooirGVIbPnXBJkqQiFOVEFWMqQ2cRLkmSVKQin6hiTOWUGUeRJEkqEcZU8oc74ZIkSSUk6pjKjrU7aF7fTOpoyqjKcSzCJUmSSkyUMZVMd4ZUd89nGlX5kHEUSZKkEufBP9FzJ1ySJEmRxlTAiSoW4ZIkSQJyME0FSnaiinEUSZIkDciYSnjcCZckSdKgjKmEwyJckiRJH8mYSvCMo0iSJGlIjKmMXF7shCdIsIlNpEkzhzlcxmV9Xm+mmWd4hhgxyijjaq7mHM4BYAtbeJmXATiTM7mBG4gTj/x3kCRJKiUDxVRSXSnKTisjnUyT6Q62WC62mErOi/A0aTaykVu4hRpqeIAHqKeeiUzsvWYqU/km3yRGjN/ze9aylm/xLTroYCtbuYM7iBPnUR6liSZmMzuHv5EkSVJp6B9TgQiiKkUSU8l5HKWNNk4/9qigglnMooWWPteMYhQxev6EkyTZ+8/QU8QnSdJNN0mSVFMd6folSZL0oaiiKoUeU8n5TngHHdRQ0/tzDTW00nrCda/xGv/Kv9JJJzdzc++1C1nID/gBceJMYxrncu6A39NIIy/xEgDxt42rSJIkhSXKiSqprhQ71u6geX0zqaOpgomq5LwIH8jxO91ZM489drObZ3iGZSyjiy6aaWYFKxjNaB7lUV7lVS7gghPeP+/YA2DDhA2h/w6SJEmlLMqJKpnuDKnuns8slKhKzuMoNdTQQUfvzx10fGSkZApTOMABOunkDd5gPOOpoopyypnJTPayN4plS5IkaQicqNJXzovwWmrZz34OcIAUKZpoop76PtfsZz+ZY39/0U473XQzhjGMZSyttPIBH5Ahwy52MYEJufg1JEmSdBLZmMqyZ5Yxc8lM4lVxBghABCY7UeW75d9lVdUq1t60lrZtbXlRlOc8jlJOOddyLQ/xEBkyzGY2E5nIdrYDMJ/5vMZrvMqrlFFGnDhLWUqMGGdxFg00cD/3U0YZk5jEXObm+DeSJEnSYDz4p0dsJStz/0eBiG2Yu4HGxsZcL0OSJElAd7Kb9beup2VDC6muFJl0uOVpRWUF591wHosfXhxq42ZtrJblLB/wtZzHUSRJklTachFTadnQQvv29vC+5CRyHkeRJEmSoo6ppLpSbPn+Fpb+dGngn30q3AmXJElS3gl7mkomnWHnz3YG+plDYREuSZKkvDRQTCVWFqN8dDmx8pEX5aE1gp4C4yiSJEnKW/1jKhBcVKWiMnelsDvhkiRJKihBRFViZTFmXDcjhNWdGotwSZIkFZyRTlSpGF3BxXdeHN4CT/b9OftmSZIkaQSGO1GlorKC+i/VUzu/NqqlnsCdcEmSJBWFk8VUYmUx4mPinHfDeSxasyjUg3pOxp1wSZIkFY1sTKV9ezub79tMYmOCVFeKisoKZlw3g4vvupi6+XW5XqZFuCRJkorLQBNV8o1xFEmSJCliFuGSJElSxCzCJUmSpIhZhEuSJEkRswiXJEmSImYRLkmSJEXMIlySJEmKmEW4JEmSFDGLcEmSJCliFuGSJElSxCzCJUmSpIhZhEuSJEkRq8j1AnLhty/9ltpYbeTfe5jDjGFM5N+r3PB+lxbvd+nxnpcW73dpCep+v8d7g75WkkX43dydk++9n/tZzvKcfLei5/0uLd7v0uM9Ly3e79ISxf02jiJJkiRFzCJckiRJiphFeITmMjfXS1CEvN+lxftderznpcX7XVqiuN+xlazMhP4tkiRJknq5Ey5JkiRFrCSno0QtQYJNbCJNmjnM4TIuy/WSFLCDHGQd63if94kRYy5z+Qyf4TCHeYzHeI/3GMc4buRGKqnM9XIVkDRp/o6/o5pqbuZm73cR66KLp3iKfewjRowbuIGP83Hvd5HawhZe5mUAzuRMbuAGkiS930VkPevZyU6qqOIO7gD4yH+HP8/zvMzLlFHGNVzDuZw74jW4Ex6yNGk2spGbuZk7uIMmmtjHvlwvSwEro4yruIo/48+4ndvZxjb2sY8XeIGpTOXP+XOmMpUXeCHXS1WAXuRFzuCM3p+938VrE5s4l3P5Ft/iG3yDMzjD+12kOuhgK1v5Ol/nDu4gTZommrzfReZCLuSrfLXPc4Pd433so4km7uAOvspX+Rk/I016xGuwCA9ZG22cfuxRQQWzmEULLblelgJWTTW19BwANYpRTGAChzhECy1cyIVAz//hm2nO4SoVpIMcJEGCOczpfc77XZyOcIQ97Om91xVUUEml97uIpUmTJEk33SRJUk2197vITGHKCX+TMdg9bqGFWcyiggrGM57TOZ022ka8BuMoIeuggxpqen+uoYZWWnO4IoXtAAd4i7eoo473eZ9qqoGeQr2TzhyvTkHZxCa+yBc5ytHe57zfxekABxjDGNaznj/wByYxiWu4xvtdpGqoYSEL+QE/IE6caUzjXM71fpeAwe5xBx2cxVm919VQQwcdI/4+d8JzIEYs10tQSI5ylEd5lKu5mtGMzvVyFJIWWqiiqvdvP1Tc0qR5i7eYz3y+wTc4jdOMIhSxLrpoppkVrOBO7uQDPuBVXs31spRngqjl3AkPWf8/LXXQ0funLBWXbrp5lEf5NJ+mgQYAPsbHOMQhqqnmEIeooirHq1QQ9rKXFlpIkCBFiqMc5XEe934XqZpjj+xOWAMNvMAL3u8i9QZvMJ7xvfdzJjPZy17vdwkY7B6HVcu5Ex6yWmrZz34OcIAUKZpoop76XC9LAcuQ4Ume5AzOYCELe5+vp55XeAWAV3jFe18kruRK7uROvs23WcpSpjKVJSzxfhepaqoZy1je4R2gp0ibwATvd5Eay1haaeUDPiBDhl3s8n6XiMHucT31NNFEihQHOMB+9lNH3Yi/z8N6IrCTnWxiExkyzGY2n+WzuV6SAraHPfw9f89EJvb+FdUVXMFZnMVa1nKQg4xlLDdyI2MYk+PVKki72MVmNveOKPR+F6e3eIuneIpuuhnPeBaxiAwZ73eR+gW/oIkmyihjEpP4El/iAz7wfheRx3iM3ezmMIepoorP83nO47xB7/FzPMev+TVllHE1VzOd6SNeg0W4JEmSFDHjKJIkSVLELMIlSZKkiFmES5IkSRGzCJckSZIiZhEuSZIkRczDeiSpQPzHXf+RcVPGnfS6H3/ux+z55Z7wFzRCl//ny/ncys/x7Mpn+eW9v8z1ciQpUhbhklRgfrfpd7z/+/cHff2jXpMk5QeLcEkqMC/81xcKYqdbkjQ4M+GSJElSxNwJl6QiNfacsazYvYL3dr/HX5/71yy8ayEXLLuA8VPHc+TgEX636Xf84ju/oGNvx4Dvn9AwgUvuvoQpn59C1cQqPjj0AW3b2tj2o238btPvBv3eaVdNY+7yuZz1mbMYc8YYut7t4t3X32XnUzvZ+tdbSR1JnfCeqolVfP67n2f6ddMZM2EMh9oPseOnO3h25bN0H+0O7H8TScoXFuGSVAKW/nQpM/5oBruf3c0fXv0DZ19yNhcuu5Bzrz6XH3/2x+zfub/P9TOun8GNj95IxegK9jXt483n36TmrBqm/btpTL92Os997zl+8Z9+ccL3XPc/rmPeN+cB0La9jd2/3E3l6ZVMmDmBK//qSpp+2sTBPQf7vGfs2WP5+ktfhxjs3byXUTWjmHzpZC79i0uZ0DCBR254JLz/YSQpRyzCJanIjZsyjorKCu6ffT/vvPYOAGXxMr704Je44JYL+PJDX2b1Rat7r686s4ovP/RlKkZX8PP/4+e8+IMXe1875/Jz+MrPvsJnv/NZ3nzhTV7/l9d7X/vMis8w75vzeP/37/PIokdo29rWZx1TPjeFIweOnLC+2bfN5uUHXuZnd/yMdDINwBnnncHt226n/kv1nL3wbPZu3hvo/yaSlGsW4ZJUYL727NcGfe3Ie0f4q/F/dcLzz33vud4CHCCdTPPPf/bP1F9fT92Cuj6F7tx/P5fRY0fz5q/e7FOAA+z55R62/812Lrn7Ei6+6+LeIjxWHuPSey4FYP3X1p9QgAPsfnb3gGs++OZB/vnP/7m3AAd4p/kdfvPQb5j/H+Yz9YqpFuGSio5FuCQVmI8aUZg8nBzw+d/8f7854bmjHUfZ+U87Of+r5zPlc1N6C91zLj8HgFd//OqAn/Xr//VrLrn7EiZfOplYWYxMOkPtvFqqJlRxcO9BXv/56wO+bzC7ntk1YE78neaePzRU11YP6fMkqRBYhEtSgRnqiMKuA10cPXh0wNfe2/0eADVn1fQ+V13XU/Qe2HVgwPcc2HWAdHeaeGWcyo9Xcvjtw4w7ZxwA+1v2D/iej3LwzYMDPn+0o2fNFaP9T5Wk4uOIQkkSmUym959jsdixJyP67nREXyRJecQiXJKKXOX4SkbVjBrwtXFTxgFwqP1Q73MdrT0jC8d/cvyg7ykrLyPZlaTr3S4A3tvzHgAfr/94QKuWpOJmES5JJeDTN3/6hOdG1Yxixh/NAPo2TWajLuffev6AnzX7T2YD8OYLb5Lp7tnFfuult+h8u5OxZ49l2lXTgly6JBUli3BJKgGX/6fLOeO8M3p/Lqso4+ofXs3ocaNpb2xn768+nD7y0gMvcbTjKOdcdg4LvrWgz+dMvmxy73Nbvr+l9/l0Ks0L/9cLANzw9zdQO7/2hDWcc/k5g+7IS1KpsdtFkgrMpX9xKRd+7cJBX//fD/9v3nj6jd6f39vzHm+99BbLX1nOrmd2cfTgUc66+CzGnTOOzrc7WXfruj7v7/xDJ+tuWcfSny7lmr++hjm3z2Ff0z6qa6uZfNlkysrLeO57z50wBeXFH7zIhJkTmPPv53D7i7fT3tjOu797t+ewnoYJjJ08lv825b/1NlxKUimzCJekAnPu1ed+5Ou/f+X3fYpwMrD2prVc+heXcv4t5zPunHEc7TjKqw+9yi++84sTTrAEaHmqhb+b93dccvclTP3CVBqWNnD00FFe/5fXe46t/+eBj63f8PUNND/ZzLxvzKNuQR2fuPATdL3bxf7Efrb9aNugoxUlqdTEVrLStnRJKkJjzxnLit0reG/3e/xw6g9zvRxJ0nHMhEuSJEkRswiXJEmSImYRLkmSJEXMTLgkSZIUMXfCJUmSpIhZhEuSJEkRswiXJEmSImYRLkmSJEXMIlySJEmKmEW4JEmSFLH/H7TJBcdwphJVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (range(0, 99))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x, loss_list, 'go--', linewidth=2, markersize=12, color='purple')\n",
    "plt.xlabel('Epoch', fontsize=22, color='white')\n",
    "plt.ylabel('Loss', fontsize=22, color='white')\n",
    "plt.gcf().set_facecolor(\"purple\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([4000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([4000, 32, 4, 4])\n",
      "Final layer:  torch.Size([4000, 10])\n",
      "Accuracy: 0.82475\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    y_test = y_test_tensor.cpu().numpy()\n",
    "    predicted = predicted.cpu()\n",
    "    \n",
    "    accuracy_cnn = accuracy_score(predicted, y_test)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy_score(predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression: 78.325%\n",
      "Accuracy of CNN/PyTorch: 82.475%\n"
     ]
    }
   ],
   "source": [
    "# Compared models\n",
    "print(f'Accuracy of LogisticRegression: {accuracy*100}%')\n",
    "print(f'Accuracy of CNN/PyTorch: {accuracy_cnn*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network did better during the image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
