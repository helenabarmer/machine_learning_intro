{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification \n",
    "\n",
    "* Dataset: [Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "* **Images**: Matrix of numbers (pixels). Each pixel holds a number we will work with\n",
    "* **Images with colors**: Multi channel. 3 values needed.\n",
    "* **Greyscale images**: Single channel images. 1 value needed.\n",
    "* Every image is 28x28 pixels.\n",
    "\n",
    "# 4 values\n",
    "\n",
    "* **List of images**: (1, 2, 3, 4)\n",
    "* **Value 1**: Number of images in the list\n",
    "* **Value 2,3**: Height and width of the image\n",
    "* **Value 4**: Number of channels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "#data = 'mnist.csv'\n",
    "data = 'https://raw.githubusercontent.com/helenabarmer/machine_learning_intro/master/Multiclass%20Classification/mnist.csv'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df[df.columns[1:]]\n",
    "\n",
    "# Labels\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>2.321200</td>\n",
       "      <td>5.457800</td>\n",
       "      <td>...</td>\n",
       "      <td>34.320800</td>\n",
       "      <td>23.071900</td>\n",
       "      <td>16.432000</td>\n",
       "      <td>17.870600</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>17.790200</td>\n",
       "      <td>8.353500</td>\n",
       "      <td>2.541600</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.06560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.525187</td>\n",
       "      <td>2.494315</td>\n",
       "      <td>2.208882</td>\n",
       "      <td>4.669183</td>\n",
       "      <td>5.657849</td>\n",
       "      <td>8.591731</td>\n",
       "      <td>15.031508</td>\n",
       "      <td>23.359019</td>\n",
       "      <td>...</td>\n",
       "      <td>57.888679</td>\n",
       "      <td>49.049749</td>\n",
       "      <td>42.159665</td>\n",
       "      <td>44.140552</td>\n",
       "      <td>51.706601</td>\n",
       "      <td>45.128107</td>\n",
       "      <td>28.765769</td>\n",
       "      <td>16.417363</td>\n",
       "      <td>7.462533</td>\n",
       "      <td>1.93403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>107.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.000400      0.010300      0.052100      0.077000   \n",
       "std        2.872425      0.024493      0.525187      2.494315      2.208882   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000      2.000000     45.000000    218.000000    185.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.208600      0.349200      0.826700      2.321200      5.457800   \n",
       "std        4.669183      5.657849      8.591731     15.031508     23.359019   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    223.000000    247.000000    218.000000    244.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     34.320800     23.071900     16.432000     17.870600   \n",
       "std    ...     57.888679     49.049749     42.159665     44.140552   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     55.000000      6.000000      0.000000      0.000000   \n",
       "max    ...    254.000000    252.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      22.860000     17.790200      8.353500      2.541600      0.629500   \n",
       "std       51.706601     45.128107     28.765769     16.417363      7.462533   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    240.000000    225.000000    205.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  10000.00000  \n",
       "mean       0.06560  \n",
       "std        1.93403  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      107.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us scale our data as we can see the variance of the mean.\n",
    "Let's scale the pictures so they are at a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fit_scaler = scaler.fit(X)\n",
    "scaled_pixels = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def display_image(features, image_label):\n",
    "\n",
    "    # Labels\n",
    "    label_names = {\n",
    "        0: 'T-shirt',\n",
    "        1: 'Trouser',\n",
    "        2: 'Pullover',\n",
    "        3: 'Dress',\n",
    "        4: 'Coat',\n",
    "        5: 'Sandal',\n",
    "        6: 'Shirt',\n",
    "        7: 'Sneaker',\n",
    "        8: 'Bag',\n",
    "        9: 'Ankle boot'\n",
    "    }\n",
    "    \n",
    "    print('This is a', label_names[image_label].lower())\n",
    "    plt.imshow(features.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test to display image\n",
    "display_image(X.loc[5].values, y.loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our data\n",
    "We will go ahead and split our data into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Helena\\Anaconda3\\envs\\pysyft\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='sag', multi_class='auto', max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 78.35%\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predict, normalize=True)\n",
    "print(f'Accuracy of model: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "CNN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 784])\n",
      "X_test:  torch.Size([4000, 784])\n",
      "y_train:  torch.Size([6000])\n",
      "y_test:  torch.Size([4000])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float)\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float)\n",
    "print(\"X_test: \", X_test_tensor.shape)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "print(\"y_train: \", y_train_tensor.shape)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "print(\"y_test: \", y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape images to 1, 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([6000, 1, 28, 28])\n",
      "X_test:  torch.Size([4000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.Tensor(X_train_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "X_test_tensor = torch.Tensor(X_test_tensor.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "print(\"X_train: \", X_train_tensor.shape)\n",
    "print(\"X_test: \", X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check number of labels: 10\n"
     ]
    }
   ],
   "source": [
    "# Input size, for grayscale 1 and for color 3\n",
    "input_size = 1\n",
    "\n",
    "# Hidden layers\n",
    "hidden_1 = 1\n",
    "hidden_2 = 32\n",
    "\n",
    "# Output values, we have 10 different labels\n",
    "print(f'Check number of labels: {len(df[\"label\"].unique())}')\n",
    "output = 10\n",
    "      \n",
    "nn_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_1, nn_size),\n",
    "            nn.BatchNorm2d(hidden_1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Layer 2\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(input_size, hidden_2, nn_size),\n",
    "            nn.BatchNorm2d(hidden_2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Final layer\n",
    "        self.final_layer = nn.Linear(512, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.layer_1(x)\n",
    "        print(\"Layer 1: \", out.shape)\n",
    "\n",
    "        out = self.layer_2(out)\n",
    "        print(\"Layer 2: \", out.shape)\n",
    "\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "\n",
    "        out = self.final_layer(out)\n",
    "        print(\"Final layer: \", out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to cuda\n",
    "model = CNN_Model()\n",
    "model.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move X and y to cuda\n",
    "X_train_tensor = X_train_tensor.to(cuda)\n",
    "X_test_tensor = X_test_tensor.to(cuda)\n",
    "\n",
    "y_train_tensor = y_train_tensor.to(cuda)\n",
    "y_test_tensor = y_test_tensor.to(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 1 Loss 2.5005218982696533\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 2 Loss 2.3022615909576416\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 3 Loss 2.1593692302703857\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 4 Loss 2.0468997955322266\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 5 Loss 1.9500854015350342\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 6 Loss 1.8621270656585693\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 7 Loss 1.7804045677185059\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 8 Loss 1.7041832208633423\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 9 Loss 1.633506178855896\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 10 Loss 1.5686057806015015\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 11 Loss 1.5096173286437988\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 12 Loss 1.4561015367507935\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 13 Loss 1.4076685905456543\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 14 Loss 1.363928198814392\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 15 Loss 1.3244540691375732\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 16 Loss 1.2887800931930542\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 17 Loss 1.2562330961227417\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 18 Loss 1.2260315418243408\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 19 Loss 1.1975486278533936\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 20 Loss 1.1703826189041138\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 21 Loss 1.1444615125656128\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 22 Loss 1.1198370456695557\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 23 Loss 1.0966156721115112\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 24 Loss 1.0748168230056763\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 25 Loss 1.0543873310089111\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 26 Loss 1.0352169275283813\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 27 Loss 1.0171372890472412\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 28 Loss 1.0000234842300415\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 29 Loss 0.9837735891342163\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 30 Loss 0.96834796667099\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 31 Loss 0.953717827796936\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 32 Loss 0.9398695230484009\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 33 Loss 0.9268599152565002\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 34 Loss 0.9144536256790161\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 35 Loss 0.9025554060935974\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 36 Loss 0.891135036945343\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 37 Loss 0.8801499605178833\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 38 Loss 0.8695794939994812\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 39 Loss 0.8594315648078918\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 40 Loss 0.8496810793876648\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 41 Loss 0.8402723670005798\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 42 Loss 0.8311665058135986\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 43 Loss 0.8223611116409302\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 44 Loss 0.813855767250061\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 45 Loss 0.8057044148445129\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 46 Loss 0.7978330850601196\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 47 Loss 0.7901610732078552\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 48 Loss 0.7826574444770813\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 49 Loss 0.7753251791000366\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 50 Loss 0.7681564092636108\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 51 Loss 0.761150062084198\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 52 Loss 0.7543154358863831\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 53 Loss 0.7476657032966614\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 54 Loss 0.7411875128746033\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 55 Loss 0.7348737716674805\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Loss 0.7287297248840332\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 57 Loss 0.7227504849433899\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 58 Loss 0.7169463634490967\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 59 Loss 0.7112935185432434\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 60 Loss 0.7058366537094116\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 61 Loss 0.7005599737167358\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 62 Loss 0.6953977942466736\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 63 Loss 0.6903253793716431\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 64 Loss 0.6853263974189758\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 65 Loss 0.6804379820823669\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 66 Loss 0.675645649433136\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 67 Loss 0.6709437370300293\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 68 Loss 0.666329026222229\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 69 Loss 0.6618000268936157\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 70 Loss 0.6573383212089539\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 71 Loss 0.6529669761657715\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 72 Loss 0.648687481880188\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 73 Loss 0.6445069313049316\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 74 Loss 0.6404070854187012\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 75 Loss 0.6363767981529236\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 76 Loss 0.6324080228805542\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 77 Loss 0.6284968852996826\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 78 Loss 0.6246483325958252\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 79 Loss 0.6208662390708923\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 80 Loss 0.6171466112136841\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 81 Loss 0.6134873032569885\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 82 Loss 0.6098817586898804\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 83 Loss 0.606336772441864\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 84 Loss 0.6028573513031006\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 85 Loss 0.5994371771812439\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 86 Loss 0.5960864424705505\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 87 Loss 0.5927811861038208\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 88 Loss 0.5895193815231323\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 89 Loss 0.5863025188446045\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 90 Loss 0.5831469893455505\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 91 Loss 0.5800548195838928\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 92 Loss 0.577012300491333\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 93 Loss 0.574006974697113\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 94 Loss 0.5710425972938538\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 95 Loss 0.5681197643280029\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 96 Loss 0.5652520656585693\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 97 Loss 0.5624321103096008\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 98 Loss 0.5596571564674377\n",
      "Layer 1:  torch.Size([6000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([6000, 32, 4, 4])\n",
      "Final layer:  torch.Size([6000, 10])\n",
      "Epoch: 99 Loss 0.5569120049476624\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "loss_list = list()\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    # Calculate output and loss\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Zero out gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pas\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch} Loss {loss.item()}')\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = (range(0, 99))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x, loss_list, 'go--', linewidth=2, markersize=12, color='purple')\n",
    "plt.xlabel('Epoch', fontsize=22, color='white')\n",
    "plt.ylabel('Loss', fontsize=22, color='white')\n",
    "plt.gcf().set_facecolor(\"purple\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:  torch.Size([4000, 1, 12, 12])\n",
      "Layer 2:  torch.Size([4000, 32, 4, 4])\n",
      "Final layer:  torch.Size([4000, 10])\n",
      "Accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    y_test = y_test_tensor.cpu().numpy()\n",
    "    predicted = predicted.cpu()\n",
    "    \n",
    "    accuracy_cnn = accuracy_score(predicted, y_test)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy_score(predicted, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression: 78.35%\n",
      "Accuracy of CNN/PyTorch: 79.05%\n"
     ]
    }
   ],
   "source": [
    "# Compared models\n",
    "print(f'Accuracy of LogisticRegression: {accuracy*100}%')\n",
    "print(f'Accuracy of CNN/PyTorch: {accuracy_cnn*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network did better during the image classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
